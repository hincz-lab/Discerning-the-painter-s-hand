{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_prob_ensemble(data, patch_idx, grpn, grpsize, total_trials):\n",
    "    '''\n",
    "    Function: load probability data, compute ensemble prediction for a given patch index\n",
    "    Input Parameters:\n",
    "        data: probability file of the format [index probability_art_1 probability_art_2 probability_art_3 probability_art_4]\n",
    "        patch_idx: patch index that we need the ensemble prediction for\n",
    "        grpn: ensemble number\n",
    "        grpsize: ensemble size \n",
    "        total_trials: total number of trials we have in the data for that particular patch size\n",
    "    Output:\n",
    "        patch_idx: patch index that we need the ensemble prediction for\n",
    "        max_prob: average confidence in that particular prediction\n",
    "        max_prob_pid: ensemble prediction for that particular patch\n",
    "        \n",
    "    '''    \n",
    "    pred_list = data[data[:,0] == patch_idx]\n",
    "    #pred_list = data[patch_idx::1110]\n",
    "    patch_pred_mean = np.mean(pred_list[np.arange(total_trials)//grpsize==grpn,1:5],axis=0)\n",
    "    max_prob = np.amax(patch_pred_mean)\n",
    "    max_prob_pid = np.argmax(patch_pred_mean)\n",
    "    return patch_idx, max_prob, max_prob_pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAIN:\n",
    "Inputs probability data files and computes ensemble accuracy\n",
    "'''\n",
    "psizes = [120,140,224]\n",
    "\n",
    "for patch_size in psizes:\n",
    "    all_idx = np.unique(np.loadtxt('/home/gxs372/ml_art_hist/height_SI_fig/PS'+repr(patch_size)+'/heapmap_p1_ps'+repr(patch_size)+'_9010.csv')[:,0])\n",
    "    \n",
    "    data1 = np.loadtxt('/home/gxs372/ml_art_hist/height_SI_fig/PS'+repr(patch_size)+'/heapmap_p1_ps'+repr(patch_size)+'_9010.csv')\n",
    "    data2 = np.loadtxt('/home/gxs372/ml_art_hist/height_SI_fig/PS'+repr(patch_size)+'/heapmap_p2_ps'+repr(patch_size)+'_9010.csv')\n",
    "    data3 = np.loadtxt('/home/gxs372/ml_art_hist/height_SI_fig/PS'+repr(patch_size)+'/heapmap_p3_ps'+repr(patch_size)+'_9010.csv')\n",
    "    data4 = np.loadtxt('/home/gxs372/ml_art_hist/height_SI_fig/PS'+repr(patch_size)+'/heapmap_p4_ps'+repr(patch_size)+'_9010.csv')\n",
    "  \n",
    "    #ensembles of 10\n",
    "    total_trials = len(data1[::len(all_idx)])\n",
    "    grpsize = 20\n",
    "    grpnmbr = total_trials//grpsize\n",
    "    \n",
    "    fi_acc = np.zeros(grpnmbr+1)\n",
    "    fi_acc[0] = patch_size\n",
    "    \n",
    "    for j in range(grpnmbr):\n",
    "        prob_list_p1 = np.zeros((len(all_idx),3))\n",
    "        prob_list_p2 = np.zeros((len(all_idx),3))\n",
    "        prob_list_p3 = np.zeros((len(all_idx),3))\n",
    "        prob_list_p4 = np.zeros((len(all_idx),3))\n",
    "\n",
    "        for i in range(len(all_idx)):\n",
    "            prob_list_p1[i] = patch_prob_ensemble(data1, i, j, grpsize, total_trials)\n",
    "            prob_list_p2[i] = patch_prob_ensemble(data2, i, j, grpsize, total_trials)\n",
    "            prob_list_p3[i] = patch_prob_ensemble(data3, i, j, grpsize, total_trials)\n",
    "            prob_list_p4[i] = patch_prob_ensemble(data4, i, j, grpsize, total_trials)\n",
    "        total_right = len(all_idx[prob_list_p1[:,2]==0])+len(all_idx[prob_list_p2[:,2]==1])+len(all_idx[prob_list_p3[:,2]==2])+len(all_idx[prob_list_p4[:,2]==3])\n",
    "        acc = total_right/( len(all_idx) *4)\n",
    "        fi_acc[j+1] = acc\n",
    "        #print(acc)\n",
    "    res = np.reshape(fi_acc,(1,grpnmbr+1))\n",
    "    with open('ensemble_analysis_100_minus.csv','a') as f:\n",
    "        np.savetxt(f, res, fmt='%s', delimiter=',')\n",
    "    print(fi_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_prob_ensemble_f(data, patch_idx, grpn, grpsize, total_trials):\n",
    "    '''\n",
    "    Function: load probability data, compute ensemble prediction for a given patch index\n",
    "    Input Parameters:\n",
    "        data: probability file of the format [index probability_art_1 probability_art_2 probability_art_3 probability_art_4]\n",
    "        patch_idx: patch index that we need the ensemble prediction for\n",
    "        grpn: ensemble number\n",
    "        grpsize: ensemble size \n",
    "        total_trials: total number of trials we have in the data for that particular patch size\n",
    "    Output:\n",
    "        max_prob_pid: ensemble prediction for that particular patch\n",
    "    '''\n",
    "    pred_list = data[data[:,0] == patch_idx]\n",
    "    #pred_list = data[patch_idx::1110]\n",
    "    patch_pred_mean = np.mean(pred_list[np.arange(total_trials)//grpsize==grpn,1:5],axis=0)\n",
    "    max_prob = np.amax(patch_pred_mean)\n",
    "    max_prob_pid = np.argmax(patch_pred_mean)\n",
    "    return max_prob_pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAIN:\n",
    "Computes Confusion Matrices for Individual Artists\n",
    "and subsequently does\n",
    "-F1 SCORE ANALYSIS\n",
    "-Recall SCORE ANALYSIS\n",
    "-Precision SCORE ANALYSIS\n",
    "'''\n",
    "\n",
    "#patch sizes to be analyzed\n",
    "psizes = [10,20,40,80,100,120,140,160,180,200,224,250] \n",
    "\n",
    "for patch_size in psizes:\n",
    "    #obtain length of files\n",
    "    all_idx = np.unique(np.loadtxt('/home/gxs372/ml_art_hist/height_SI_fig/PS'+repr(patch_size)+'/heapmap_p1_ps'+repr(patch_size)+'_9010.csv')[:,0])\n",
    "    \n",
    "    #load probability files\n",
    "    data1 = np.loadtxt('/home/gxs372/ml_art_hist/height_SI_fig/PS'+repr(patch_size)+'/heapmap_p1_ps'+repr(patch_size)+'_9010.csv')\n",
    "    data2 = np.loadtxt('/home/gxs372/ml_art_hist/height_SI_fig/PS'+repr(patch_size)+'/heapmap_p2_ps'+repr(patch_size)+'_9010.csv')\n",
    "    data3 = np.loadtxt('/home/gxs372/ml_art_hist/height_SI_fig/PS'+repr(patch_size)+'/heapmap_p3_ps'+repr(patch_size)+'_9010.csv')\n",
    "    data4 = np.loadtxt('/home/gxs372/ml_art_hist/height_SI_fig/PS'+repr(patch_size)+'/heapmap_p4_ps'+repr(patch_size)+'_9010.csv')\n",
    "\n",
    "    total_trials = len(data1[::len(all_idx)])\n",
    "    if patch_size==10 :\n",
    "        grpsize = 10\n",
    "    else :\n",
    "        grpsize = 20   \n",
    "        \n",
    "    grpnmbr = total_trials//grpsize\n",
    "    \n",
    "    #Initiate arrays\n",
    "    f1 = np.zeros((4,grpnmbr+1))\n",
    "    f1[:,0] = np.repeat(patch_size,4)\n",
    "    precision = np.zeros((4,grpnmbr+1))\n",
    "    precision[:,0] = np.repeat(patch_size,4)\n",
    "    recall = np.zeros((4,grpnmbr+1))\n",
    "    recall[:,0] = np.repeat(patch_size,4)\n",
    "\n",
    "    for j in range(grpnmbr):\n",
    "        prob_list_p1 = np.zeros((len(all_idx),1))\n",
    "        prob_list_p2 = np.zeros((len(all_idx),1))\n",
    "        prob_list_p3 = np.zeros((len(all_idx),1))\n",
    "        prob_list_p4 = np.zeros((len(all_idx),1))\n",
    "\n",
    "        for i in range(len(all_idx)):\n",
    "            prob_list_p1[i] = patch_prob_ensemble_f(data1, i, j, grpsize, total_trials)\n",
    "            prob_list_p2[i] = patch_prob_ensemble_f(data2, i, j, grpsize, total_trials)\n",
    "            prob_list_p3[i] = patch_prob_ensemble_f(data3, i, j, grpsize, total_trials)\n",
    "            prob_list_p4[i] = patch_prob_ensemble_f(data4, i, j, grpsize, total_trials)\n",
    "\n",
    "        y_true = np.repeat(np.array([0,1,2,3]),len(prob_list_p1))\n",
    "        y_pred = np.concatenate((np.reshape(prob_list_p1,[len(prob_list_p1)]),np.reshape(prob_list_p2,[len(prob_list_p1)]),np.reshape(prob_list_p3,[len(prob_list_p1)]),np.reshape(prob_list_p4,[len(prob_list_p1)])))\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        #print(cm)\n",
    "        for i in range(4):\n",
    "\n",
    "            tp = cm[i,i] \n",
    "            fp = np.sum(cm[i]) - tp\n",
    "            fn = np.sum(cm[:,i]) - tp\n",
    "            tn = np.sum(cm) - tp - fp - fn\n",
    "\n",
    "            f1[i,j+1] = tp/(tp+0.5*(fp+fn))\n",
    "            precision[i,j+1] = tp/(tp+fp)\n",
    "            recall[i,j+1] = tp/(tp+fn)\n",
    "            \n",
    "\n",
    "    res_1 = np.reshape(f1[0],(1,grpnmbr+1))    \n",
    "    res_2 = np.reshape(f1[1],(1,grpnmbr+1))    \n",
    "    res_3 = np.reshape(f1[2],(1,grpnmbr+1))    \n",
    "    res_4 = np.reshape(f1[3],(1,grpnmbr+1))    \n",
    "    \n",
    "    with open('rev_f1_ensemble_art_1.csv','a') as f:\n",
    "        np.savetxt(f, res_1, fmt='%s', delimiter=',')\n",
    "    \n",
    "    with open('rev_f1_ensemble_art_2.csv','a') as f:\n",
    "        np.savetxt(f, res_2, fmt='%s', delimiter=',')    \n",
    "    \n",
    "    with open('rev_f1_ensemble_art_3.csv','a') as f:\n",
    "        np.savetxt(f, res_3, fmt='%s', delimiter=',')    \n",
    "    \n",
    "    with open('rev_f1_ensemble_art_4.csv','a') as f:\n",
    "        np.savetxt(f, res_4, fmt='%s', delimiter=',')      \n",
    "                                   \n",
    "    prec_1 = np.reshape(precision[0],(1,grpnmbr+1))    \n",
    "    prec_2 = np.reshape(precision[1],(1,grpnmbr+1))    \n",
    "    prec_3 = np.reshape(precision[2],(1,grpnmbr+1))    \n",
    "    prec_4 = np.reshape(precision[3],(1,grpnmbr+1))  \n",
    "    \n",
    "    rec_1 = np.reshape(recall[0],(1,grpnmbr+1))    \n",
    "    rec_2 = np.reshape(recall[1],(1,grpnmbr+1))    \n",
    "    rec_3 = np.reshape(recall[2],(1,grpnmbr+1))    \n",
    "    rec_4 = np.reshape(recall[3],(1,grpnmbr+1))        \n",
    "    \n",
    "    with open('precision_ensemble_art_1.csv','a') as f:\n",
    "        np.savetxt(f, prec_1, fmt='%s', delimiter=',')\n",
    "    \n",
    "    with open('precision_ensemble_art_2.csv','a') as f:\n",
    "        np.savetxt(f, prec_2, fmt='%s', delimiter=',')    \n",
    "    \n",
    "    with open('precision_ensemble_art_3.csv','a') as f:\n",
    "        np.savetxt(f, prec_3, fmt='%s', delimiter=',')    \n",
    "    \n",
    "    with open('precision_ensemble_art_4.csv','a') as f:\n",
    "        np.savetxt(f, prec_4, fmt='%s', delimiter=',')    \n",
    "        \n",
    "        \n",
    "    with open('recall_ensemble_art_1.csv','a') as f:\n",
    "        np.savetxt(f, rec_1, fmt='%s', delimiter=',')\n",
    "    \n",
    "    with open('recall_ensemble_art_2.csv','a') as f:\n",
    "        np.savetxt(f, rec_2, fmt='%s', delimiter=',')    \n",
    "    \n",
    "    with open('recall_ensemble_art_3.csv','a') as f:\n",
    "        np.savetxt(f, rec_3, fmt='%s', delimiter=',')    \n",
    "    \n",
    "    with open('recall_ensemble_art_4.csv','a') as f:\n",
    "        np.savetxt(f, rec_4, fmt='%s', delimiter=',')      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
