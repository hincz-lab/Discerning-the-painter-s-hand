{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.feature_extraction.image import extract_patches\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, AveragePooling2D, Dropout, Input\n",
    "from tensorflow.keras import regularizers, optimizers, models, layers, losses, metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "from skimage import img_as_float\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "def load_data(file_path):\n",
    "    data = cv2.imread(file_path,cv2.IMREAD_UNCHANGED)\n",
    "    data = (data/65535)*255\n",
    "    return data\n",
    "\n",
    "\n",
    "# divide each channel of the painting to patches then concatenate channels, also get the list of\n",
    "# corresponding labels (painter id)\n",
    "def get_patches(data, patch_size, painter_id):\n",
    "    pc1 = extract_patches(data[:,:,0], patch_shape = patch_size, extraction_step = patch_size)\n",
    "    pc1 = pc1.reshape(-1, patch_size, patch_size)\n",
    "    pc2 = extract_patches(data[:,:,1], patch_shape = patch_size, extraction_step = patch_size)\n",
    "    pc2 = pc2.reshape(-1, patch_size, patch_size)\n",
    "    pc3 = extract_patches(data[:,:,2], patch_shape = patch_size, extraction_step = patch_size)\n",
    "    pc3 = pc3.reshape(-1, patch_size, patch_size)\n",
    "    pc1_reshaped = pc1.reshape(*pc1.shape,1)\n",
    "    pc2_reshaped = pc2.reshape(*pc2.shape,1)\n",
    "    pc3_reshaped = pc3.reshape(*pc3.shape,1)\n",
    "    patches = np.concatenate((pc1_reshaped,pc2_reshaped,pc3_reshaped),axis=3)\n",
    "\n",
    "    \n",
    "    labels = []\n",
    "    def get_label(painter_id, patch_len):\n",
    "        labels.clear()\n",
    "        labels.append(painter_id * patch_len)\n",
    "        return labels\n",
    "\n",
    "    list_len = np.ones(len(patches))\n",
    "    y_list = get_label(painter_id, list_len)\n",
    "    y_list = np.reshape(y_list,(len(patches),1)) \n",
    "                        \n",
    "    return patches, y_list  # use this when shuffle=False\n",
    "\n",
    "\n",
    "# preprocess each patches to prepare for transfer learning by subtracting the mean [103.939, 116.779, 123.68]\n",
    "def preprocess_patches(patch_list):\n",
    "    patches = preprocess_input(patch_list)\n",
    "    return patches\n",
    "\n",
    "# resize patches to 224*224\n",
    "def resize_patches(patch_list):   \n",
    "    resize_patches = [None]*len(patch_list)\n",
    "    for i in range(len(patch_list)):\n",
    "        resize_patches[i] = cv2.resize(patch_list[i],(224, 224))\n",
    "    new_list = np.asarray(resize_patches, dtype=np.float64)\n",
    "    return new_list\n",
    "    \n",
    "# put all the previous step together\n",
    "def process_pipeline(file_path, patch_size, painter_id):\n",
    "    data = load_data(file_path)\n",
    "    patch_list, labels = get_patches(data, patch_size, painter_id)\n",
    "    preprocessed_patches = preprocess_patches(patch_list)\n",
    "    resized_patches = resize_patches(preprocessed_patches)\n",
    "    return resized_patches, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATCH SIZE: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fxj53/.local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:86: FutureWarning: Function extract_patches is deprecated; The function feature_extraction.image.extract_patches has been deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATCH SIZE: 200\n",
      "Train on 1296 samples, validate on 144 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.48611, saving model to weights.best.hdf5\n",
      "1296/1296 - 19s - loss: 1.7954 - accuracy: 0.4005 - val_loss: 1.2740 - val_accuracy: 0.4861\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.48611 to 0.52083, saving model to weights.best.hdf5\n",
      "1296/1296 - 12s - loss: 1.2314 - accuracy: 0.5008 - val_loss: 1.1648 - val_accuracy: 0.5208\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.52083 to 0.59028, saving model to weights.best.hdf5\n",
      "1296/1296 - 12s - loss: 1.1326 - accuracy: 0.5579 - val_loss: 1.0726 - val_accuracy: 0.5903\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.59028\n",
      "1296/1296 - 12s - loss: 1.0261 - accuracy: 0.5995 - val_loss: 1.0139 - val_accuracy: 0.5764\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.59028\n",
      "1296/1296 - 12s - loss: 0.9576 - accuracy: 0.6404 - val_loss: 1.0350 - val_accuracy: 0.5833\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.59028\n",
      "1296/1296 - 12s - loss: 0.8889 - accuracy: 0.6674 - val_loss: 0.9990 - val_accuracy: 0.5833\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.59028\n",
      "1296/1296 - 12s - loss: 0.8295 - accuracy: 0.6890 - val_loss: 1.0550 - val_accuracy: 0.5556\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.59028 to 0.61806, saving model to weights.best.hdf5\n",
      "1296/1296 - 12s - loss: 0.8084 - accuracy: 0.6937 - val_loss: 0.9928 - val_accuracy: 0.6181\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.61806\n",
      "1296/1296 - 12s - loss: 0.7615 - accuracy: 0.7222 - val_loss: 0.9830 - val_accuracy: 0.6111\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.61806\n",
      "1296/1296 - 12s - loss: 0.7248 - accuracy: 0.7423 - val_loss: 0.9922 - val_accuracy: 0.6042\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.61806\n",
      "1296/1296 - 12s - loss: 0.6732 - accuracy: 0.7531 - val_loss: 1.0109 - val_accuracy: 0.5972\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.61806 to 0.63889, saving model to weights.best.hdf5\n",
      "1296/1296 - 12s - loss: 0.6692 - accuracy: 0.7685 - val_loss: 0.9682 - val_accuracy: 0.6389\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.63889\n",
      "1296/1296 - 12s - loss: 0.6358 - accuracy: 0.7801 - val_loss: 1.0726 - val_accuracy: 0.6181\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.63889 to 0.65278, saving model to weights.best.hdf5\n",
      "1296/1296 - 12s - loss: 0.5746 - accuracy: 0.8187 - val_loss: 0.9583 - val_accuracy: 0.6528\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.65278 to 0.66667, saving model to weights.best.hdf5\n",
      "1296/1296 - 13s - loss: 0.5540 - accuracy: 0.8248 - val_loss: 1.0086 - val_accuracy: 0.6667\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 12s - loss: 0.5391 - accuracy: 0.8333 - val_loss: 1.0324 - val_accuracy: 0.6250\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 12s - loss: 0.5498 - accuracy: 0.8233 - val_loss: 1.0158 - val_accuracy: 0.6597\n",
      "Epoch 18/25\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 12s - loss: 0.5112 - accuracy: 0.8295 - val_loss: 1.0518 - val_accuracy: 0.6389\n",
      "Epoch 19/25\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 12s - loss: 0.5204 - accuracy: 0.8503 - val_loss: 0.9896 - val_accuracy: 0.6458\n",
      "Epoch 20/25\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 12s - loss: 0.4794 - accuracy: 0.8511 - val_loss: 1.0388 - val_accuracy: 0.6250\n",
      "Epoch 21/25\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 12s - loss: 0.4461 - accuracy: 0.8750 - val_loss: 1.0113 - val_accuracy: 0.6319\n",
      "Epoch 22/25\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 12s - loss: 0.4573 - accuracy: 0.8688 - val_loss: 1.1303 - val_accuracy: 0.6458\n",
      "Epoch 23/25\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 12s - loss: 0.4130 - accuracy: 0.8912 - val_loss: 1.1531 - val_accuracy: 0.6111\n",
      "Epoch 24/25\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 12s - loss: 0.4301 - accuracy: 0.8796 - val_loss: 1.0753 - val_accuracy: 0.6042\n",
      "Epoch 25/25\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 12s - loss: 0.4370 - accuracy: 0.8742 - val_loss: 1.0515 - val_accuracy: 0.6667\n",
      "Train on 1296 samples, validate on 144 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 20s - loss: 1.7705 - accuracy: 0.3873 - val_loss: 1.3385 - val_accuracy: 0.3958\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 17s - loss: 1.3469 - accuracy: 0.4097 - val_loss: 1.1921 - val_accuracy: 0.4583\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 17s - loss: 1.1786 - accuracy: 0.4954 - val_loss: 1.0960 - val_accuracy: 0.5278\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 17s - loss: 1.1809 - accuracy: 0.5131 - val_loss: 1.1179 - val_accuracy: 0.5694\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 17s - loss: 1.0475 - accuracy: 0.5610 - val_loss: 1.1235 - val_accuracy: 0.5278\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 17s - loss: 1.0203 - accuracy: 0.6080 - val_loss: 0.9338 - val_accuracy: 0.6458\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 17s - loss: 0.9097 - accuracy: 0.6381 - val_loss: 0.9829 - val_accuracy: 0.6250\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66667\n",
      "1296/1296 - 17s - loss: 0.8427 - accuracy: 0.6883 - val_loss: 0.8210 - val_accuracy: 0.6667\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.66667 to 0.68750, saving model to weights.best.hdf5\n",
      "1296/1296 - 18s - loss: 0.7888 - accuracy: 0.7052 - val_loss: 0.8056 - val_accuracy: 0.6875\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.7328 - accuracy: 0.7215 - val_loss: 0.9186 - val_accuracy: 0.6806\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.7340 - accuracy: 0.7253 - val_loss: 0.9860 - val_accuracy: 0.5625\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.6529 - accuracy: 0.7515 - val_loss: 0.9598 - val_accuracy: 0.6597\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.6067 - accuracy: 0.7909 - val_loss: 1.0465 - val_accuracy: 0.6319\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.5887 - accuracy: 0.8071 - val_loss: 1.0060 - val_accuracy: 0.5833\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.5434 - accuracy: 0.8125 - val_loss: 1.2144 - val_accuracy: 0.6111\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.4049 - accuracy: 0.8519 - val_loss: 0.9046 - val_accuracy: 0.6319\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.3495 - accuracy: 0.8974 - val_loss: 1.1551 - val_accuracy: 0.6181\n",
      "Epoch 18/25\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.3577 - accuracy: 0.8889 - val_loss: 1.3272 - val_accuracy: 0.6319\n",
      "Epoch 19/25\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.2968 - accuracy: 0.9151 - val_loss: 1.3980 - val_accuracy: 0.5486\n",
      "Epoch 20/25\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.2457 - accuracy: 0.9336 - val_loss: 1.4974 - val_accuracy: 0.5972\n",
      "Epoch 21/25\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.2335 - accuracy: 0.9360 - val_loss: 1.7595 - val_accuracy: 0.5486\n",
      "Epoch 22/25\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.3035 - accuracy: 0.9159 - val_loss: 1.5487 - val_accuracy: 0.5764\n",
      "Epoch 23/25\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.2365 - accuracy: 0.9491 - val_loss: 1.4717 - val_accuracy: 0.6111\n",
      "Epoch 24/25\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.2050 - accuracy: 0.9483 - val_loss: 1.2508 - val_accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.68750\n",
      "1296/1296 - 17s - loss: 0.1335 - accuracy: 0.9745 - val_loss: 1.7258 - val_accuracy: 0.6181\n",
      "RESULT: 200, 0.5208333333333334\n",
      "\n",
      "PATCH SIZE: 200\n",
      "Train on 1296 samples, validate on 144 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.40278, saving model to weights.best.hdf5\n",
      "1296/1296 - 13s - loss: 1.9367 - accuracy: 0.3565 - val_loss: 1.3881 - val_accuracy: 0.4028\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.40278 to 0.56944, saving model to weights.best.hdf5\n",
      "1296/1296 - 12s - loss: 1.3069 - accuracy: 0.4468 - val_loss: 1.1513 - val_accuracy: 0.5694\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.56944 to 0.58333, saving model to weights.best.hdf5\n",
      "1296/1296 - 12s - loss: 1.1218 - accuracy: 0.5486 - val_loss: 1.1008 - val_accuracy: 0.5833\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.58333\n",
      "1296/1296 - 12s - loss: 1.0136 - accuracy: 0.6049 - val_loss: 1.0728 - val_accuracy: 0.5486\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.58333 to 0.62500, saving model to weights.best.hdf5\n",
      "1296/1296 - 12s - loss: 0.9693 - accuracy: 0.6250 - val_loss: 1.0024 - val_accuracy: 0.6250\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.62500 to 0.69444, saving model to weights.best.hdf5\n",
      "1296/1296 - 13s - loss: 0.9393 - accuracy: 0.6466 - val_loss: 0.9519 - val_accuracy: 0.6944\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.69444\n",
      "1296/1296 - 12s - loss: 0.8544 - accuracy: 0.6782 - val_loss: 0.9332 - val_accuracy: 0.6597\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.69444\n",
      "1296/1296 - 12s - loss: 0.8321 - accuracy: 0.6890 - val_loss: 0.9155 - val_accuracy: 0.6458\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.69444\n",
      "1296/1296 - 12s - loss: 0.7540 - accuracy: 0.7215 - val_loss: 0.9320 - val_accuracy: 0.6736\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.69444 to 0.70833, saving model to weights.best.hdf5\n",
      "1296/1296 - 12s - loss: 0.7557 - accuracy: 0.7245 - val_loss: 0.9265 - val_accuracy: 0.7083\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 12s - loss: 0.7282 - accuracy: 0.7361 - val_loss: 0.9045 - val_accuracy: 0.6806\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 12s - loss: 0.6922 - accuracy: 0.7400 - val_loss: 0.9604 - val_accuracy: 0.6944\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 12s - loss: 0.6651 - accuracy: 0.7654 - val_loss: 0.9534 - val_accuracy: 0.6667\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 12s - loss: 0.6476 - accuracy: 0.7631 - val_loss: 1.0247 - val_accuracy: 0.6875\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 12s - loss: 0.5567 - accuracy: 0.8248 - val_loss: 1.0023 - val_accuracy: 0.6944\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 12s - loss: 0.5548 - accuracy: 0.8179 - val_loss: 0.9593 - val_accuracy: 0.6736\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 12s - loss: 0.5409 - accuracy: 0.8218 - val_loss: 1.0133 - val_accuracy: 0.6389\n",
      "Epoch 18/25\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 12s - loss: 0.5292 - accuracy: 0.8326 - val_loss: 0.9959 - val_accuracy: 0.6667\n",
      "Epoch 19/25\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 12s - loss: 0.4940 - accuracy: 0.8526 - val_loss: 0.9862 - val_accuracy: 0.6458\n",
      "Epoch 20/25\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 12s - loss: 0.5087 - accuracy: 0.8372 - val_loss: 1.0859 - val_accuracy: 0.6944\n",
      "Epoch 21/25\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 12s - loss: 0.4992 - accuracy: 0.8565 - val_loss: 1.1294 - val_accuracy: 0.6736\n",
      "Epoch 22/25\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 12s - loss: 0.4746 - accuracy: 0.8619 - val_loss: 1.0586 - val_accuracy: 0.6806\n",
      "Epoch 23/25\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 12s - loss: 0.4562 - accuracy: 0.8688 - val_loss: 1.1048 - val_accuracy: 0.6875\n",
      "Epoch 24/25\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 12s - loss: 0.4400 - accuracy: 0.8681 - val_loss: 1.0918 - val_accuracy: 0.6736\n",
      "Epoch 25/25\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 12s - loss: 0.4240 - accuracy: 0.8827 - val_loss: 1.2210 - val_accuracy: 0.6875\n",
      "Train on 1296 samples, validate on 144 samples\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 18s - loss: 1.5601 - accuracy: 0.3765 - val_loss: 1.5331 - val_accuracy: 0.2639\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 17s - loss: 1.2639 - accuracy: 0.4545 - val_loss: 1.1109 - val_accuracy: 0.5139\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 17s - loss: 1.1821 - accuracy: 0.5108 - val_loss: 1.2613 - val_accuracy: 0.4653\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 17s - loss: 1.2788 - accuracy: 0.4306 - val_loss: 1.2485 - val_accuracy: 0.4306\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 17s - loss: 1.1482 - accuracy: 0.4969 - val_loss: 1.2752 - val_accuracy: 0.4514\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 17s - loss: 1.0505 - accuracy: 0.5633 - val_loss: 1.0807 - val_accuracy: 0.5208\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 17s - loss: 1.0400 - accuracy: 0.5718 - val_loss: 1.1438 - val_accuracy: 0.5139\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 17s - loss: 1.0406 - accuracy: 0.5779 - val_loss: 1.0302 - val_accuracy: 0.5833\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 17s - loss: 0.9683 - accuracy: 0.5965 - val_loss: 1.0705 - val_accuracy: 0.5069\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 17s - loss: 0.8991 - accuracy: 0.6227 - val_loss: 0.9447 - val_accuracy: 0.6458\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 17s - loss: 0.8519 - accuracy: 0.6497 - val_loss: 0.9886 - val_accuracy: 0.6528\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.70833\n",
      "1296/1296 - 17s - loss: 0.7804 - accuracy: 0.6690 - val_loss: 0.9203 - val_accuracy: 0.6181\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.70833 to 0.74306, saving model to weights.best.hdf5\n",
      "1296/1296 - 18s - loss: 0.6751 - accuracy: 0.7191 - val_loss: 1.0038 - val_accuracy: 0.7431\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74306\n",
      "1296/1296 - 17s - loss: 0.6611 - accuracy: 0.7392 - val_loss: 1.2057 - val_accuracy: 0.6319\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74306\n",
      "1296/1296 - 17s - loss: 0.5877 - accuracy: 0.7716 - val_loss: 1.1924 - val_accuracy: 0.6806\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74306\n",
      "1296/1296 - 17s - loss: 0.8047 - accuracy: 0.7037 - val_loss: 1.3061 - val_accuracy: 0.5694\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74306\n",
      "1296/1296 - 17s - loss: 0.6129 - accuracy: 0.7585 - val_loss: 1.2766 - val_accuracy: 0.6528\n",
      "Epoch 18/25\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74306\n",
      "1296/1296 - 17s - loss: 0.4845 - accuracy: 0.8117 - val_loss: 1.0599 - val_accuracy: 0.5903\n",
      "Epoch 19/25\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74306\n",
      "1296/1296 - 17s - loss: 0.4674 - accuracy: 0.8156 - val_loss: 1.6899 - val_accuracy: 0.6111\n",
      "Epoch 20/25\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74306\n",
      "1296/1296 - 17s - loss: 0.3720 - accuracy: 0.8665 - val_loss: 1.3669 - val_accuracy: 0.6458\n",
      "Epoch 21/25\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74306\n",
      "1296/1296 - 17s - loss: 0.2677 - accuracy: 0.9205 - val_loss: 2.0237 - val_accuracy: 0.6458\n",
      "Epoch 22/25\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74306\n",
      "1296/1296 - 17s - loss: 0.2427 - accuracy: 0.9159 - val_loss: 1.4144 - val_accuracy: 0.6319\n",
      "Epoch 23/25\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74306\n",
      "1296/1296 - 17s - loss: 0.2300 - accuracy: 0.9228 - val_loss: 1.4042 - val_accuracy: 0.6528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74306\n",
      "1296/1296 - 17s - loss: 0.1530 - accuracy: 0.9522 - val_loss: 2.2128 - val_accuracy: 0.6042\n",
      "Epoch 25/25\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74306\n",
      "1296/1296 - 17s - loss: 0.1776 - accuracy: 0.9576 - val_loss: 1.7481 - val_accuracy: 0.6736\n",
      "RESULT: 200, 0.49722222222222223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p1a_imf_arr = ['emd_painting_1_imf_1.png','emd_painting_1_imf_2.png','emd_painting_1_imf_3.png','emd_painting_1_imf_4.png','emd_painting_1_imf_5.png']\n",
    "p1b_imf_arr = ['emd_painting_2_imf_1.png','emd_painting_2_imf_2.png','emd_painting_2_imf_3.png','emd_painting_2_imf_4.png','emd_painting_2_imf_5.png']\n",
    "p1c_imf_arr = ['emd_painting_3_imf_1.png','emd_painting_3_imf_2.png','emd_painting_3_imf_3.png','emd_painting_3_imf_4.png','emd_painting_3_imf_5.png']\n",
    "p2a_imf_arr = ['emd_painting_4_imf_1.png','emd_painting_4_imf_2.png','emd_painting_4_imf_3.png','emd_painting_4_imf_4.png','emd_painting_4_imf_5.png']\n",
    "p2b_imf_arr = ['emd_painting_5_imf_1.png','emd_painting_5_imf_2.png','emd_painting_5_imf_3.png','emd_painting_5_imf_4.png','emd_painting_5_imf_5.png']\n",
    "p2c_imf_arr = ['emd_painting_6_imf_1.png','emd_painting_6_imf_2.png','emd_painting_6_imf_3.png','emd_painting_6_imf_4.png','emd_painting_6_imf_5.png']\n",
    "p3a_imf_arr = ['emd_painting_7_imf_1.png','emd_painting_7_imf_2.png','emd_painting_7_imf_3.png','emd_painting_7_imf_4.png','emd_painting_7_imf_5.png']\n",
    "p3b_imf_arr = ['emd_painting_8_imf_1.png','emd_painting_8_imf_2.png','emd_painting_8_imf_3.png','emd_painting_8_imf_4.png','emd_painting_8_imf_5.png']\n",
    "p3c_imf_arr = ['emd_painting_9_imf_1.png','emd_painting_9_imf_2.png','emd_painting_9_imf_3.png','emd_painting_9_imf_4.png','emd_painting_9_imf_5.png']\n",
    "p4a_imf_arr = ['emd_painting_10_imf_1.png','emd_painting_10_imf_2.png','emd_painting_10_imf_3.png','emd_painting_10_imf_4.png','emd_painting_10_imf_5.png']\n",
    "p4b_imf_arr = ['emd_painting_11_imf_1.png','emd_painting_11_imf_2.png','emd_painting_11_imf_3.png','emd_painting_11_imf_4.png','emd_painting_11_imf_5.png']\n",
    "p4c_imf_arr = ['emd_painting_12_imf_1.png','emd_painting_12_imf_2.png','emd_painting_12_imf_3.png','emd_painting_12_imf_4.png','emd_painting_12_imf_5.png']\n",
    "\n",
    "\n",
    "for imf_i in [3]: #range(len(p1a_imf_arr)): # loop through imfs, imf_i = 0-4 representing imf1-5\n",
    "    \n",
    "    psizes = [200] #patch size in pixels\n",
    "\n",
    "    for patch_size in psizes:\n",
    "        print('PATCH SIZE: '+repr(patch_size))\n",
    "        # get a list of patches (x) with corresponding painter if (y) for all 12 paintings\n",
    "        p1a_x, p1a_y = process_pipeline(p1a_imf_arr[imf_i], patch_size, 0)\n",
    "        p1b_x, p1b_y = process_pipeline(p1b_imf_arr[imf_i], patch_size, 0)\n",
    "        p1c_x, p1c_y = process_pipeline(p1c_imf_arr[imf_i], patch_size, 0)\n",
    "        p2a_x, p2a_y = process_pipeline(p2a_imf_arr[imf_i], patch_size, 1)\n",
    "        p2b_x, p2b_y = process_pipeline(p2b_imf_arr[imf_i], patch_size, 1)\n",
    "        p2c_x, p2c_y = process_pipeline(p2c_imf_arr[imf_i], patch_size, 1)\n",
    "        p3a_x, p3a_y = process_pipeline(p3a_imf_arr[imf_i], patch_size, 2)\n",
    "        p3b_x, p3b_y = process_pipeline(p3b_imf_arr[imf_i], patch_size, 2)\n",
    "        p3c_x, p3c_y = process_pipeline(p3c_imf_arr[imf_i], patch_size, 2)\n",
    "        p4a_x, p4a_y = process_pipeline(p4a_imf_arr[imf_i], patch_size, 3)\n",
    "        p4c_x, p4c_y = process_pipeline(p4c_imf_arr[imf_i], patch_size, 3)\n",
    "        p4_b = cv2.imread(p4b_imf_arr[imf_i],cv2.IMREAD_UNCHANGED)\n",
    "        p4_b = (p4_b/65535)*255\n",
    "        p4_b = cv2.rotate(p4_b, cv2.ROTATE_180) # this painting is upside down so needs to be rotated\n",
    "        p4b_x, p4b_y = get_patches(p4_b, patch_size, 3)\n",
    "        p4b_x = resize_patches(preprocess_patches(p4b_x))\n",
    "\n",
    "        x_train_val = np.concatenate((p1a_x, p1c_x, \n",
    "                                      p2a_x, p2c_x, \n",
    "                                      p3a_x, p3c_x, \n",
    "                                      p4a_x, p4c_x))\n",
    "        y_train_val = np.concatenate((p1a_y, p1c_y, \n",
    "                                      p2a_y, p2c_y, \n",
    "                                      p3a_y, p3c_y, \n",
    "                                      p4a_y, p4c_y))\n",
    "        del(p1a_x,p1a_y,p2a_x,p2a_y,p3a_x,p3a_y,p4a_x,p4a_y)\n",
    "        del(p1c_x,p1c_y,p2c_x,p2c_y,p3c_x,p3c_y,p4c_x,p4c_y)\n",
    "\n",
    "\n",
    "        foldnum=20\n",
    "\n",
    "        for fold in range(0, foldnum):\n",
    "            print('PATCH SIZE: '+repr(patch_size))\n",
    "\n",
    "            x_train,x_val,y_train,y_val = train_test_split(x_train_val, y_train_val, test_size=0.1)\n",
    "\n",
    "            x_test = np.concatenate((p1b_x, p2b_x, p3b_x, p4b_x))\n",
    "\n",
    "            # one-hot encode y\n",
    "            y_train = to_categorical(y_train, num_classes=None)\n",
    "            y_val = to_categorical(y_val, num_classes=None)\n",
    "\n",
    "            y_test = np.concatenate((p1b_y, p2b_y, p3b_y, p4b_y))\n",
    "            y_test = to_categorical(y_test, num_classes=None)\n",
    "\n",
    "            # get index for all the patches in the testing painting\n",
    "            test_idx = np.arange(len(p1b_x)).reshape(len(p1b_x),1)\n",
    "\n",
    "\n",
    "            #################\n",
    "            #if run into \"value error\", copy the rest of the code to a new cell and rerun it\n",
    "            # \"value error\" happens when the frozen network performs better than the network with layers unlocked\n",
    "            #################\n",
    "\n",
    "            baseModel = VGG16(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "            model = models.Sequential()\n",
    "            model.add(baseModel)\n",
    "            model.add(layers.AveragePooling2D(pool_size=(3, 3)))\n",
    "            model.add(layers.Flatten())\n",
    "            model.add(layers.Dropout(0.25))\n",
    "            model.add(layers.Dense(64, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "            model.add(layers.Dropout(0.25))\n",
    "            model.add(layers.Dense(4, activation=\"softmax\"))\n",
    "\n",
    "            for layer in baseModel.layers[:]:\n",
    "                layer.trainable = False\n",
    "\n",
    "\n",
    "            model.compile(optimizer=optimizers.Adam(lr = 0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            filepath= \"weights.best.hdf5\"\n",
    "            checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "            callbacks_list = [checkpoint]\n",
    "            \n",
    "            try:\n",
    "                # train ONLY top layers \n",
    "                history = model.fit(x_train, y_train, epochs=25, batch_size=32, validation_data=(x_val,y_val),shuffle=True,callbacks=callbacks_list, verbose=2)\n",
    "\n",
    "                #load the best top model\n",
    "                model.load_weights(filepath)\n",
    "\n",
    "                # Make last two blocks of the baseModel trainable:\n",
    "                for layer in baseModel.layers[:11]:\n",
    "                    layer.trainable = False\n",
    "                for layer in baseModel.layers[11:]:\n",
    "                    layer.trainable = True\n",
    "\n",
    "\n",
    "                # Compile frozen baseModel + unfrozen top block + my top layer\n",
    "                model.compile(optimizer=optimizers.Adam(lr = 0.0001),\n",
    "                              loss='categorical_crossentropy',\n",
    "                              metrics=['accuracy'])\n",
    "\n",
    "                #train with a slower learning rate\n",
    "                history = model.fit(x_train, y_train, epochs=25, batch_size=32, validation_data=(x_val,y_val),shuffle=True,callbacks=callbacks_list,verbose=2)\n",
    "\n",
    "                try:\n",
    "                    model.load_weights(filepath)\n",
    "\n",
    "                    model.compile(optimizer=optimizers.Adam(lr = 0.0001), loss='categorical_crossentropy', \n",
    "                              metrics=['accuracy'])\n",
    "\n",
    "                    '''   \n",
    "                    if os.path.exists(filepath):\n",
    "                        os.remove(\"demofile.txt\")\n",
    "                    else:\n",
    "                        print(\"The file does not exist\")\n",
    "\n",
    "\n",
    "                    path_del = (filepath)     \n",
    "                    try:\n",
    "                        os.rmdir(filepath)\n",
    "                    except OSError:\n",
    "                        print (\"Deletion of the file %s failed\" % filepath)\n",
    "                    else:\n",
    "                        print (\"Successfully deleted the file %s\" % filepath)\n",
    "                    '''\n",
    "\n",
    "                    y_pred = model.predict(x_test)\n",
    "                    ypred = np.argmax(y_pred, axis=1)\n",
    "                    ytest = np.argmax(y_test, axis=1)\n",
    "                    \n",
    "                    # resulting coufusion matrix\n",
    "                    cm = confusion_matrix(ytest, ypred)\n",
    "                    cm_flatten = cm.flatten()\n",
    "                    ps_cm = np.insert(cm_flatten,0,patch_size)\n",
    "                    ps_cm = ps_cm.reshape(1,17)\n",
    "\n",
    "                    test_accuracy = (np.trace(cm))/len(ytest)\n",
    "                    print('RESULT: '+repr(patch_size)+', '+repr(test_accuracy)+'\\n')\n",
    "\n",
    "                    p1predict = model.predict(p1b_x)\n",
    "                    p2predict = model.predict(p2b_x)\n",
    "                    p3predict = model.predict(p3b_x)\n",
    "                    p4predict = model.predict(p4b_x)\n",
    "\n",
    "                    p1_predict = np.concatenate([test_idx,p1predict], axis=1)\n",
    "                    p2_predict = np.concatenate([test_idx,p2predict], axis=1)\n",
    "                    p3_predict = np.concatenate([test_idx,p3predict], axis=1)\n",
    "                    p4_predict = np.concatenate([test_idx,p4predict], axis=1)\n",
    "\n",
    "                    report = classification_report(ytest, ypred,output_dict=True)\n",
    "                    p1_report = np.asarray([report['0']['f1-score']])\n",
    "                    p1_report = np.insert(p1_report,0,patch_size)\n",
    "                    p1_report = p1_report.reshape(1,2)\n",
    "\n",
    "                    p2_report = np.asarray([report['1']['f1-score']])\n",
    "                    p2_report = np.insert(p2_report,0,patch_size)\n",
    "                    p2_report = p2_report.reshape(1,2)\n",
    "\n",
    "                    p3_report = np.asarray([report['2']['f1-score']])\n",
    "                    p3_report = np.insert(p3_report,0,patch_size)\n",
    "                    p3_report = p3_report.reshape(1,2)\n",
    "\n",
    "                    p4_report = np.asarray([report['3']['f1-score']])\n",
    "                    p4_report = np.insert(p4_report,0,patch_size)\n",
    "                    p4_report = p4_report.reshape(1,2)\n",
    "\n",
    "                    overall = np.asarray([report['accuracy'],report['macro avg']['f1-score'],report['weighted avg']['f1-score'] ])\n",
    "                    overall = np.insert(overall,0,patch_size)\n",
    "                    overall = overall.reshape(1,4)\n",
    "\n",
    "\n",
    "                    with open('p1_report_ps'+repr(patch_size)+'_emd_mike_individual_imf'+repr(imf_i+1)+'.csv','a') as f:\n",
    "                        np.savetxt(f, p1_report, fmt='%s')\n",
    "                    with open('p2_report_ps'+repr(patch_size)+'_emd_mike_individual_imf'+repr(imf_i+1)+'.csv','a') as f:\n",
    "                        np.savetxt(f, p2_report, fmt='%s')\n",
    "                    with open('p3_report_ps'+repr(patch_size)+'_emd_mike_individual_imf'+repr(imf_i+1)+'.csv','a') as f:\n",
    "                        np.savetxt(f, p3_report, fmt='%s')\n",
    "                    with open('p4_report_ps'+repr(patch_size)+'_emd_mike_individual_imf'+repr(imf_i+1)+'.csv','a') as f:\n",
    "                        np.savetxt(f, p4_report, fmt='%s')\n",
    "                    with open('overall_report_ps'+repr(patch_size)+'_emd_mike_individual_imf'+repr(imf_i+1)+'.csv','a') as f:\n",
    "                        np.savetxt(f, overall, fmt='%s')\n",
    "\n",
    "\n",
    "                    with open('heapmap_p1_ps'+repr(patch_size)+'_emd_mike_individual_imf'+repr(imf_i+1)+'.csv','a') as f:\n",
    "                        np.savetxt(f, p1_predict, fmt='%s')\n",
    "                    with open('heapmap_p2_ps'+repr(patch_size)+'_emd_mike_individual_imf'+repr(imf_i+1)+'.csv','a') as f:\n",
    "                        np.savetxt(f, p2_predict, fmt='%s')\n",
    "                    with open('heapmap_p3_ps'+repr(patch_size)+'_emd_mike_individual_imf'+repr(imf_i+1)+'.csv','a') as f:\n",
    "                        np.savetxt(f, p3_predict, fmt='%s')\n",
    "                    with open('heapmap_p4_ps'+repr(patch_size)+'_emd_mike_individual_imf'+repr(imf_i+1)+'.csv','a') as f:\n",
    "                        np.savetxt(f, p4_predict, fmt='%s')\n",
    "                    with open('cm_height_vgg16_ps'+repr(patch_size)+'_emd_mike_individual_imf'+repr(imf_i+1)+'.csv','a') as f:\n",
    "                        np.savetxt(f, ps_cm, fmt='%s')\n",
    "\n",
    "                    with open(\"accuracy_vgg16_ps\"+repr(patch_size)+'_emd_mike_individual_imf'+repr(imf_i+1)+'.csv', \"a\") as myfile:\n",
    "                        myfile.write(repr(patch_size)+','+repr(test_accuracy)+'\\n')\n",
    "\n",
    "                    del(p1predict,p2predict,p3predict,p4predict,p1_predict,p2_predict,p3_predict,p4_predict,model,ps_cm,cm,history)\n",
    "\n",
    "                except:\n",
    "                    pass   \n",
    "            except:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_accuracy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
